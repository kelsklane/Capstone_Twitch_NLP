{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![twitch](Images/twitchlogo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitch Hate Chat Identification\n",
    "---\n",
    "Author: [Kelsey Lane](kelsklane@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "---\n",
    "This project aims to better identify hate chats on Twitch livestreams. A subset of data consisting of four streamers and nine total streams from [this Harvard database](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VE0IVQ) is used in this project. These streams occurred during April - June of 2018. Sentiment analysis is used to identify negative comments which can be used to flag hate chats as they are sent. The relative importance of different words that predict hate chats can also be pulled from the model to help build a better filter. The packages used for this project can be seen in the environment file provided in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Overview\n",
    "---\n",
    "The data I'm using for this project are chat messages scraped from Twitch livestreams with metadata about the time the message was sent, how far into the stream the message was sent and more. This is suited for the business problem as the aim is to help Twitch more efficiently screen and filter out hate messages, so modeling the sentiment of the messages is a step towards this. To prep the data I used VADER from NLTK to assign a negative or not negative label to each chat. As for cleaning the data I filtered out as many messages sent by bots as I could and got rid of any messages with links using regular expressions, as these are often just advertisements and not real chats. For the tokenization process, I used NLTK's Tweet tokenizer as chats are similar in structure to tweets. I left capitalization and stop words in, as short, casual messages can perform better when retaining this information. Finally, unnecessary punctuation is filtered out and the remaining words are lemmatized to help reduce the number of features. \n",
    "\n",
    "The main two models used for the sentiment analysis are the Multinomial Bayes and Logistic Regression models from sklearn, as these often work well with sentiment analysis and are simple enough to run effectively with the amount of data I have. Sklearn's CountVectorizer was used alongside a custom tokenization function to break the chats up and these vectorizers were tuned using a GridSearch to alter the maximum number of features in the dataset, the frequency cutoff for the higher frequency words, whether bigrams should be used or not, and if the words should all be lowercase or not. The logistic regression model was also tuned, but the only change from the default was to increase the number of iterations. While iterating throughout the models, a train test split was performed and the training data was further cross validated using sklearn's `cross_validate` library. The final model is a logistic regression that has an accuracy of 95% with a recall of 76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "---\n",
    "Twitch has an issue with cyberbullying in their chats. According to a [survey done in 2018](https://blog.streamelements.com/streamelements-analysis-on-twitch-bullying-c3f2b2240318), over a quarter of people using Twitch have seen some type of bullying in chat messages. In addition, over 13% of streamers have felt bullied at some point. While Twitch has measures in place for combating bullying, only 26.4% of people thought they were effective. This bullying can have serious consequences for the mental health of not only the streamers, but also the viewers participating in the chat. Therefore, in an effort to help Twitch's safety operations team better tackle this issue and create a safer platform, I propose using a sentiment analysis model to help better identify hate chats. This model can help flag these chats faster for moderators to view and deal with. Words common to hate messages can also be identified and added to existing filters to strengthen them. This can help combat the bullying issue present on Twitch's platform while also creating a more welcoming environment, especially for BIPOC and LGBTQ+ people that are often the target of this bullying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "---\n",
    "The dataset for this project comes from a [Harvard study](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VE0IVQ) and contains chat logs from 50 different streamers with around 25 streams per streamer. As the total original data contains too many rows to efficiently run on my computer, I paired the dataset down to four streamers with nine streams total. This means there are two streams per streamer. However, KingRichard has three streams to keep the number of chats at about 25,000 for each person. In the end, this resulted in a dataset with 102,700 rows where each row is a unique chat. When creating the dataset read in below, only chats with the user commenter type were kept, as chats from admins and moderators are not going to contain hate messages. The `fragments` column from the original dataset was broken out into a `twitch_chat` column and `emotes` column to better manipulate the data. The original dataset also contained chats that were edited, though it was never made clear if this was by users or moderators editing the chat for content. Due to this uncertainty and the fact there weren't that many edited chats, any edited rows are dropped. Finally, any chats that start with an exclamation point are filtered out, as on Twitch these are commands used to call bots and are not actual comments. The final dataset was created by merging the nine streams together and dropping the `fragments` and `updated_at` columns, as these supply no additional information. This smaller dataset is imported in the cell below and the code for generating it can be found in the Merge_datasets notebook in the notebook folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports libraries for labeling data\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Imports libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Imports libraries for text cleaning and manipulation\n",
    "import nltk\n",
    "import re\n",
    "import collections\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Imports libraries for modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, recall_score, accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Imports dataset\n",
    "df = pd.read_csv('data/small_merged_chats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in the process of saving the modified dataframe and opening it again eight of the chats get corrupted and become NaNs, so these rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets rid of rows that got turned to NaNs\n",
    "df = df.dropna(subset = ['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While doing data exploration, I found some bot messages sending links to the streamers Patreon or Discord server, as well as advertisements for other Twitch streams. In an effort to narrow the data down to only human messages, any chat message with a link is dropped from the dataset. While this may drop some non-bot related messages, it seemed to be the cleanest way to identify these false rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of chats with links (often promo/not real messages)\n",
    "def ad(chat):\n",
    "    result = False\n",
    "    #Change result to True if link present in chat\n",
    "    result = bool(re.search(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', chat))\n",
    "    result = bool(re.search(r'http\\S+', chat))\n",
    "    return result\n",
    "\n",
    "#Makes ad column and gets rid of any ad messages\n",
    "df['is_ad'] = df['body'].apply(ad)\n",
    "df = df[df['is_ad'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in preparation for generating the labels for the data, certain emotes are truncated down to one form. Some emotes have different variants that are simply cosmetic, but the way they get rendered in text is as different \"words.\" To reduce the number of extra words that get counted, the most popular emotes with a lot of variations are replaced with their basic form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes popular emojis to one type so no variants ie) pog + pogChamp -> pog + pog\n",
    "def emoji_shorten(chat):\n",
    "    chat = re.sub(r'(?i) \\bpog(\\w)*\\b |\\bpog(\\w)*\\b', 'pog', chat)\n",
    "    chat = re.sub(r'(?i) \\blul(\\w)*\\b |\\blul(\\w)*\\b', 'lul', chat)\n",
    "    chat = re.sub(r'(?i) \\bkappa(\\w)*\\b |\\bkappa(\\w)*\\b', 'kappa', chat)\n",
    "    return chat\n",
    "\n",
    "#Creates new column with emojis shortened to simple form\n",
    "df['chats'] = df.body.apply(lambda x: emoji_shorten(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is used to create the target labels for the data. As Twitch has a lot of platform specific words, some of the more popular ones are added to VADER's lexicon to generate more accurate labels. The full added vocabulary is included below, where the sentiment values are calculated from [this study](https://dl.acm.org/doi/10.1145/3365523) that had people rate the positive, negative, or neutral sentiment of various Twitch emotes and slang. Some variations of words that are intentional misspellings of existing ones are also included below and marked with the same sentiment value as the original word, ie) nice vs. noice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words to add to VADER\n",
    "new_words = {\n",
    "    'noice': 1.8,\n",
    "    'scum': -2.0,\n",
    "    'kap': 0.5,\n",
    "    'kappa': 0.5,\n",
    "    'lul': 1.8,\n",
    "    'omegalol': 1.8,\n",
    "    'strats': 2.0,\n",
    "    'rekt': 0,\n",
    "    'owo': 1.0,\n",
    "    'tweaker': -2.3,\n",
    "    'pog': 2.8,\n",
    "    'pag': 2.8,\n",
    "    'incel': -3.1,\n",
    "    'tilted': -0.7,\n",
    "    'feelsbadman': -2.6,\n",
    "    'feelsgoodman': 3.7,\n",
    "    'trash': -2.0,\n",
    "    'rip': -1.2,\n",
    "    'ez': 1.9,\n",
    "    'clap': 2.7,\n",
    "    'hyperbruh': -0.6,\n",
    "    'f': 0.5,\n",
    "    'F': 0.5,\n",
    "    #Discord changed to 0 as it refers to a messaging platform\n",
    "    'discord': 0,\n",
    "    'PJSalt': -1.2,\n",
    "    'Kreygasm': 2.8,\n",
    "    'kreygasm': 2.8,\n",
    "    'homo': -3.5,\n",
    "    'clip': 0.5,\n",
    "    'rAcIsM': -3.1,\n",
    "    'based': 2.0,\n",
    "    'Based': 2.0,\n",
    "    'PepeHands': -1.7,\n",
    "    'WutFace': -1.7,\n",
    "    'FailFish': -2.0,\n",
    "    'BabyRage': -1.6,\n",
    "    'ANELE': -0.8,\n",
    "    'haHAA': -0.5,\n",
    "    'ResidentSleeper': -1.2,\n",
    "    'cmonBruh': -1.0,\n",
    "    #Change sentiment to neutral as looking for hate specifically\n",
    "    ':(': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the labels are generated using VADER below. Each chat is sorted into either a positive, neutral, or negative sentiment list. A one is assigned to any chat in the negative list, while a 0 is assigned to any positive or neutral chat in the dataframe to create the target. Since I am only looking for chats with hate, the positive and neutral chats are lumped together. The normalized count of these labels is printed as well, and there is a class imbalance present in the data that will need to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.89037\n",
       "1    0.10963\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates labels for data\n",
    "# WARNING: Takes a while to run\n",
    "polarity = 0\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "for chat in df.chats:\n",
    "    #Sets up chat for analysis and initializes VADER object\n",
    "    analysis = TextBlob(chat)\n",
    "    vad = SentimentIntensityAnalyzer()\n",
    "    #New words get added to vocabulary\n",
    "    vad.lexicon.update(new_words)\n",
    "    score = vad.polarity_scores(chat)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    #Assigns chat to either positive, negative, or neutral\n",
    "    if neg > pos:\n",
    "        negative_list.append(chat)\n",
    "    elif pos > neg:\n",
    "        positive_list.append(chat) \n",
    "    elif pos == neg:\n",
    "        neutral_list.append(chat)\n",
    "\n",
    "#Labels the data based on VADER results\n",
    "df[\"label\"] = np.where(df[\"chats\"].isin(negative_list), 1, 0)\n",
    "df.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there are a lot of limitations present with the data. For one, the VADER labeling assigns chats as negative or not negative, but these negative chats aren't all hate. However, there is no neat way to filter out specifically the hate messages from ones that aren’t. While expanding VADER's lexicon can help with identification, models built with these labels will pick up on other negative chats in addition to hate chats. Another limitation is that words can be intentionally misspelled to bypass the filters on Twitch. However, due to the wide variation in misspellings and potential overlap with other words, I didn't attempt to spell check chats to target these words. As a result, there may also be hate messages that slip by. Another limitation is the potential presence of other bot chats aside from the advertisements filtered out earlier. As different streamers can set up custom bots that say different things in response to user prompts, it's not easy to find and filter for all these messages. The streamers included in this dataset are also all well known. As a result, they have more moderators and may actually regulate their chats better when compared to smaller or mid-sized streamers. Therefore, scraping and looking at Twitch chats for smaller streamers would make for more robust data. Finally, the lack of diversity in streamers in the dataset I pulled from originally means that these hate messages may not fully encompass what’s on the platform. As a result, hate directed towards certain minority groups may be underrepresented in the data and not picked up by the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "---\n",
    "In an effort to help better identify hate chats, additional features were added to the data. The first is the time of day of the stream, as streams at night may receive more or less hate than those during the day. Due to the overwhelming amount of streams occurring at night, the stream are split into three groups. A stream is marked as being in the day if it falls between 7am to 8pm. After that, night is broken into night, consisting of 8pm to midnight, and late night, which is midnight to 7am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the hour of stream at time of comment\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['hour'] = df.created_at.apply(lambda x: x.hour)\n",
    "\n",
    "#Sorts chat into day/night/late night based on hour chat was made\n",
    "def day_night(hour):\n",
    "    if (hour >= 7) and (hour < 20):\n",
    "        return 'Day'\n",
    "    elif (hour >= 20) and (hour <= 23):\n",
    "        return 'Night'\n",
    "    else:\n",
    "        return 'Late Night'\n",
    "    \n",
    "#Creates the column\n",
    "df['day_night'] = df.hour.apply(day_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other features added were if the original chat included an emote, as some emotes require the user to subscribe to the Twitch streamer. Therefore, these users are less likely to comment hate messages and this information could help improve the model. The ratio of capital letters in the chat is also included as its’ own feature to help capture the energy of the sentiment. As some models make all the chats lowercase, this information can get lost so it is preserved and amplified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did the user include an emote\n",
    "def any_emojis(emotes):\n",
    "    if emotes[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#Adds if chat contains emojis or not\n",
    "df['any_emojis'] = df.emotes.apply(any_emojis)\n",
    "    \n",
    "    \n",
    "#Ratio capital to length tweet\n",
    "def capital_letter_ratio(chat):\n",
    "    if type(chat) == float:\n",
    "        return 0\n",
    "    if len(chat) == 0:\n",
    "        return 0\n",
    "    capital_count = 0\n",
    "    for c in chat:\n",
    "        if c.isupper():\n",
    "            capital_count += 1\n",
    "    return capital_count / len(chat)\n",
    "\n",
    "#Adds ratio of capital letters\n",
    "df['cap_ratio'] = df.twitch_chat.apply(capital_letter_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature added is `offset_percent`. In the original dataset, offset represents how many seconds from the start of the stream the chat was made. To make this consistent, the offset was divided by the length of the stream to get the percent value for how far into the stream the comment was made. This is a useful feature to add as certain events in the stream may have triggered people to leave hate chats, and thus the timing the chat was sent may give us useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabs the max offset value as the length of stream and the stream associated with it\n",
    "graph = df.groupby(['video_id'])['offset'].max()\n",
    "videos = list(graph.index)\n",
    "max_time = list(graph.values)\n",
    "\n",
    "#Creates list of sets of the max time for each stream\n",
    "time_pairings = []\n",
    "for i, v in enumerate(videos):\n",
    "    time_pairings.append((videos[i], max_time[i]))\n",
    "\n",
    "#Finds the length of the stream for each chat\n",
    "def find_time(video):\n",
    "    for pair in time_pairings:\n",
    "        if video == pair[0]:\n",
    "            return pair[1]\n",
    "\n",
    "#Creates the length of stream and uses that to make the offset percent\n",
    "df['max_time'] = df.video_id.apply(find_time)\n",
    "df['offset_percent'] = (df.offset / df.max_time) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last feature added is the total comments made by each user during a stream. While it's not clear if these anonymized ids are kept between streams, they are treated as unique to each stream. This can be a useful feature as sometimes people may spam hate comments, so the quantity of chats made by a user may help distinguish hate chats from regular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts the number of comments made by each user\n",
    "counter = collections.Counter(df.commenter_id)\n",
    "\n",
    "#Adds the number of comments made by the user\n",
    "def commenter_count(id):\n",
    "    return counter[id]\n",
    "df['total_comments'] = df.commenter_id.apply(commenter_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves the dataset with a lot of features. Many are leftover columns used to create other ones, so the dataset is paired down to the relevant columns. The `body` and `twitch_chat` columns are dropped as they have the same information as the processed `chat` column. `channel_id` and `commenter_id` are dropped as they provide redundant information with other columns in the dataset. For similar reasons, `is_ad`, `created_at`, `offset`, `hour`, `emotes`, and `max_time` are dropped as they were used as intermediaries to create other columns or to drop irrelevant rows and aren't necessarily useful on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops irrelevant columns\n",
    "df = df.drop(columns = ['body', 'channel_id', 'commenter_id', 'is_ad', 'created_at', \n",
    "                  'offset', 'hour', 'max_time', 'twitch_chat', 'emotes'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves the final dataset with eight columns. `label` is the target column while `chats` now contains the processed chat message to be analyzed. The remaining six columns are extra features that can help enhance the performance of the model. `day_night`, `any_emojis`, `cap_ratio`, `offset_percent`, and `total_comments` are kept as engineered features. Finally, `video_id` is kept as a variable, since different streams can attract different amounts of hate. As this is a categorical column, it is converted to a string below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes id to string\n",
    "df['video_id'] = df['video_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the function used to tokenize the chats in the vectorizers is included below. Any non-English characters are stripped from any chats as the emotes are represented as words, so there is no worry of getting rid of emoji-related information by doing this. The chats are then tokenized using NLTK's Tweet Tokenizer to help capture the nuances of causal language present on Twitch. Finally, any punctuation that is not likely to indicate emotion are stripped from the tokens and the resulting words are lemmatized, as word variations aren't important for differentiating chats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces pos tags with lemmatize compatable tags\n",
    "def pos_replace(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "#Makes list of punctuation to exclude, keeps certain symbols\n",
    "punct = list(string.punctuation)\n",
    "keep_punct = ['?', '!', '@', ',', '.']\n",
    "punct = [p for p in punct if p not in keep_punct]\n",
    "\n",
    "#Removes non-ASCII characters (aka emojis that cant be converted to original symbol)\n",
    "def remove_junk(tweet):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "\n",
    "def chat_tokenizer(doc):\n",
    "    #Gets rid of weird characters\n",
    "    doc = remove_junk(doc)\n",
    "    #Tokenizes using NLTK Twitter Tokenizer as chats like tweets\n",
    "    chat_token = TweetTokenizer(strip_handles = True)\n",
    "    doc = chat_token.tokenize(doc)\n",
    "    #Strips extra puntuation I don't want to keep\n",
    "    doc = [w for w in doc if w not in punct]\n",
    "    #Lemmatizes tokens\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(w[0], pos_replace(w[1])) for w in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model\n",
    "The first simple model in this case is a Naive Bayes model that takes in only the chat messages. This just gives us a raw estimation of how well we could expect a model to do based on chats alone. Bayes also works well for language analysis, so it makes for a good first model. While recall is the metric used, I’ve printed accuracy as well to get a sense of how well the models fit. The negative chats are also SMOTEd to account for class imbalance. I tried mixtures of under and oversampling, but simply using SMOTE returned the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.5494953832939661\n",
      "Training Accuracy: 0.9084582927620902\n",
      "Validation Recall:0.825469626429447\n",
      "Validation Accuracy:0.8824277831872769\n"
     ]
    }
   ],
   "source": [
    "#Creates features and target then performs train test split\n",
    "y = df['label']\n",
    "X = df['chats']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "#Pipeline for processing and fitting model\n",
    "mnb_cv = imbpipeline(steps=[\n",
    "    ('preproc', CountVectorizer(lowercase = False, tokenizer = chat_tokenizer)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "mnb_cv.fit(X_train, y_train)\n",
    "preds = mnb_cv.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", mnb_cv.score(X_train, y_train))\n",
    "#Cross validates model and prints average result\n",
    "scoring = {\n",
    "    'acc': make_scorer(accuracy_score),\n",
    "    'rec': 'recall'\n",
    "}\n",
    "scores = cross_validate(mnb_cv, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes models\n",
    "For the next iteration I changed out the vectorizer for the Tf_idf vectorizer to see if including information regarding document frequency would improve the recall. The model continues to use only the chats as input, since adding in the additional features would not improve model performance. I also tested Complement Bayes to see if it would perform better, as that version of Bayes is intended to help with cases of class imbalance more. The performance was worse than the Multinomial Bayes though, so it is not included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.4457721082943108\n",
      "Training Accuracy: 0.8643427458617332\n",
      "Validation Recall:0.915461336112242\n",
      "Validation Accuracy:0.8210321324245374\n"
     ]
    }
   ],
   "source": [
    "#Pipeline for processing and fitting model\n",
    "mnb_tfidf = imbpipeline(steps=[\n",
    "    ('preproc', TfidfVectorizer(lowercase = False, tokenizer = chat_tokenizer)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "mnb_tfidf.fit(X_train, y_train)\n",
    "preds = mnb_tfidf.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", mnb_tfidf.score(X_train, y_train))\n",
    "\n",
    "#Cross validates model and prints average result\n",
    "scores = cross_validate(mnb_tfidf, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to CountVectorizer, Tf_idf performs worse on recall and accuracy, so I stuck with Count Vectorizer for Multinomial Bayes. I then used a GridSearch to tune the parameters of the vectorizer and the tuned model is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.5494953832939661\n",
      "Training Accuracy: 0.9084582927620902\n",
      "Validation Recall:0.825469626429447\n",
      "Validation Accuracy:0.8824277831872769\n"
     ]
    }
   ],
   "source": [
    "#Pipeline for processing and fitting model\n",
    "mnb_tuned = imbpipeline(steps=[\n",
    "    ('preproc', CountVectorizer(max_df = .5, lowercase = False, tokenizer = chat_tokenizer)),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "mnb_tuned.fit(X_train, y_train)\n",
    "preds = mnb_tuned.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", mnb_tuned.score(X_train, y_train))\n",
    "#Cross validates model and prints average result\n",
    "scores = cross_validate(mnb_tuned, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "After tuning the Multinomial Bayes model above, there wasn't really any improvement from the baseline. Therefore, I opted to try a different model to see if I could improve my results. The next model I tried was Logistic Regression, as it was another simple model that could run in a reasonable amount of time and works well with text analysis. I added the additional features back in and the untuned model is shown below. The numerical columns are scaled as leaving these unscaled could affect the performance of the logistic regression. I also had to increase the max iterations of the model to ensure that all the cross validation folds would complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.8368109623170352\n",
      "Training Accuracy: 0.9747484582927621\n",
      "Validation Recall:0.8349547618696036\n",
      "Validation Accuracy:0.9553391755923402\n"
     ]
    }
   ],
   "source": [
    "#Creates a new train test split with the added features\n",
    "y = df['label']\n",
    "X = df[['chats', 'video_id', 'day_night', \n",
    "            'any_emojis', 'cap_ratio', 'offset_percent', 'total_comments']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 213)\n",
    "\n",
    "#Pipeline for processing and fitting model\n",
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(lowercase = False, tokenizer = chat_tokenizer), 'chats'),\n",
    "    ('ohe', OneHotEncoder(), ['video_id', 'day_night']),\n",
    "    ('ss', StandardScaler(), ['any_emojis', 'cap_ratio', 'offset_percent', 'total_comments'])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "logreg = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('lr', LogisticRegression(max_iter = 10000, random_state = 213))\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", logreg.score(X_train, y_train))\n",
    "\n",
    "#Cross validates model and prints average result\n",
    "scores = cross_validate(logreg, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the Bayes models, the recall and accuracy of the logistic regression are much higher and more consistent, indicating a better model. The accuracy scores are also fairly close, so there doesn't seem to be much overfitting here. I ran a GridSearch to find the optimal model parameters. As the tuning of logistic regression model resulted in the default metrics being the best, the GridSearch for the vectorizer parameters is included below instead. The tuned model is then ran right after the GridSearch to see the updated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preproc__cv__lowercase': True,\n",
       " 'preproc__cv__max_df': 0.5,\n",
       " 'preproc__cv__max_features': 8000,\n",
       " 'preproc__cv__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates parameters to test\n",
    "params = {\n",
    "    'preproc__cv__max_features': [None, 4000, 8000],\n",
    "    'preproc__cv__max_df': [.5, .8, 1],\n",
    "    'preproc__cv__ngram_range': [(1,1), (2,2)],\n",
    "    'preproc__cv__lowercase': [False, True]\n",
    "}\n",
    "\n",
    "#Fits gridsearch on model and prints out the best parameters\n",
    "search = GridSearchCV(logreg, param_grid = params, scoring = scoring, cv = 3, refit = 'rec')\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.7988183456839575\n",
      "Training Accuracy: 0.9679844206426484\n",
      "Validation Recall:0.8732520193145404\n",
      "Validation Accuracy:0.9558195391106784\n"
     ]
    }
   ],
   "source": [
    "#Pipeline for processing and fitting model\n",
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(lowercase = True, max_df = .5, max_features = 8000, tokenizer = chat_tokenizer), 'chats'),\n",
    "    ('ohe', OneHotEncoder(), ['video_id', 'day_night']),\n",
    "    ('ss', StandardScaler(), ['any_emojis', 'cap_ratio', 'offset_percent', 'total_comments'])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "logreg_tune = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('lr', LogisticRegression(max_iter = 10000, random_state = 213))\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "logreg_tune.fit(X_train, y_train)\n",
    "preds = logreg_tune.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", logreg_tune.score(X_train, y_train))\n",
    "\n",
    "#Cross validates model and prints average result\n",
    "scores = cross_validate(logreg_tune, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty comparable to the untuned logistic regression. While the accuracy scores are closer, the recall scores are more consistent for the untuned version, so that is the final version I will go with. The assumption test for the logistic regression is included below and it is not met since there is not a linear relationship between the variable and the log-odds.  However, though research this doesn't seem to be uncommon for logistic regression models when used for text analysis, so I am not concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-e5143d9e8a07>:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  log_odds = np.log(pred / (1 - pred))\n",
      "<ipython-input-34-e5143d9e8a07>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  log_odds = np.log(pred / (1 - pred))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grabs probabilities and calculates log odds\n",
    "pred = logreg.predict_proba(X_train)[:, 0]\n",
    "log_odds = np.log(pred / (1 - pred))\n",
    "#Plots log odds versus continuous variable to check for linearity\n",
    "#Only one variable is tested as assumption is not met\n",
    "plt.scatter(x = X_train['offset_percent'], y = log_odds)\n",
    "plt.xlabel(\"offset_percent\")\n",
    "plt.ylabel(\"Log-odds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "Finally, I tried a random forest classifier to see if an ensemble model would perform better than the logistic regression. I also tuned this model using a GridSearch and the resulting parameters are used below. While the training recall and accuracy of the random forest are better, it seems to overfit more and the recall for the validation set is much worse. As a result, I opted to stick with the untuned logistic regression as my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Recall: 0.995819397993311\n",
      "Training Accuracy: 0.998286270691334\n",
      "Validation Recall:0.4155823508358173\n",
      "Validation Accuracy:0.9305679974034404\n"
     ]
    }
   ],
   "source": [
    "#Pipeline for processing and fitting model\n",
    "count_vec = ColumnTransformer([\n",
    "    ('cv', CountVectorizer(lowercase = False, tokenizer = chat_tokenizer), 'chats'),\n",
    "    ('ohe', OneHotEncoder(), ['video_id', 'day_night'])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "rfc_tune = imbpipeline(steps=[\n",
    "    ('preproc', count_vec),\n",
    "    ('smote', SMOTE(sampling_strategy = 'minority', random_state = 213)),\n",
    "    ('rf', RandomForestClassifier(min_samples_split = 10, random_state = 213))\n",
    "])\n",
    "\n",
    "#Fits model and prints training score\n",
    "rfc_tune.fit(X_train, y_train)\n",
    "preds = rfc_tune.predict(X_train)\n",
    "print(\"Training Recall:\", recall_score(preds, y_train))\n",
    "print(\"Training Accuracy:\", rfc_tune.score(X_train, y_train))\n",
    "#Cross validates model and prints average result\n",
    "scores = cross_validate(rfc_tune, X_train, y_train, cv = 5, scoring = scoring)\n",
    "print(\"Validation Recall:\" + str(np.mean(scores['test_rec'])))\n",
    "print(\"Validation Accuracy:\" + str(np.mean(scores['test_acc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---\n",
    "The main metric used to evaluate this is recall as I wanted to weight the model against false negatives. Since chats are ultimately being flagged for manual review, mislabeling some neutral and positive chats as negative is a fair tradeoff for capturing as many negative chats as possible. The results for the test set are displayed below, with the final model reaching a recall of 76%. The confusion matrix for this model is also printed to get a sense of how well the model does overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall: 0.7553497285212393\n",
      "Test Accuracy: 0.9522492697176241\n"
     ]
    }
   ],
   "source": [
    "#Test results for final model\n",
    "preds = logreg.predict(X_test)\n",
    "print(\"Test Recall:\", recall_score(preds, y_test))\n",
    "print(\"Test Accuracy:\", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plts confusion matric for test data\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "cmdis = ConfusionMatrixDisplay(cm)\n",
    "cmdis.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model overall does fairly well. Due to the recall score and labels coming from VADER, I would recommend implementing the model as a tool for moderators to use to help them sort through chats more efficiently. Therefore, the final model could help flag potential hate comments that would inform moderators faster of potentially problematic chats. Furthermore, the log odds of certain words predicting a negative chat can be drawn out from the model. These can be used to decide what words might be good to add to the chat filter to help improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "Overall, this model has high potential as a tool to help streamers and moderators identify hate faster. This model can also help strengthen existing filters to make the system more effective. On its own though, the model is still lacking in fully tackling the hate speech problem present on Twitch. Going forward, it would therefore be useful to get more accurate labels for the data to help train a more useable model. It would also be useful to model other languages. Finally, training models for different streaming categories would also be useful, as word contexts change depending on what’s being streamed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "---\n",
    "#### Data:\n",
    "Kim, J. (2019, August 1). Twitch.tv chat log data. Harvard Dataverse. Retrieved November 30, 2021, from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FVE0IVQ. \n",
    "\n",
    "#### Sources:\n",
    "Würzburg, K. K. J.-M.-U., Kobs, K., Würzburg, J.-M.-U., Würzburg, A. Z. J.-M.-U., Zehe, A., Würzburg, A. B. J.-M.-U., Bernstetter, A., Würzburg, J. C. J.-M.-U., Chibane, J., Würzburg, J. P. J.-M.-U., Pfister, J., Würzburg, J. T. J.-M.-U., Tritscher, J., Würzburg, A. H. J.-M.-U., Hotho, A., University, S., &amp; Metrics, O. M. V. A. (2020, May 1). Emote-controlled: Obtaining implicit viewer feedback through emote-based sentiment analysis on comments of popular Twitch.tv channels. ACM Transactions on Social Computing. Retrieved November 30, 2021, from https://dl.acm.org/doi/10.1145/3365523. \n",
    "\n",
    "Yosilewitz, A. (2018, August 6). Streamelements analysis on Twitch bullying. Medium. Retrieved November 30, 2021, from https://blog.streamelements.com/streamelements-analysis-on-twitch-bullying-c3f2b2240318. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

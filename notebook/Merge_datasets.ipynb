{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "---\n",
    "This is the notebook used to create the dataset used in modeling. The original data imported below comes from [this Harvard study](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VE0IVQ). This notebook is included on the Github for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific datasets used\n",
    "kingrichard = pd.read_pickle('../data/ICWSM19_data/kingrichard.pkl')\n",
    "scarra = pd.read_pickle('../data/ICWSM19_data/scarra.pkl')\n",
    "xchocobars = pd.read_pickle('../data/ICWSM19_data/xchocobars.pkl')\n",
    "tfue = pd.read_pickle('../data/ICWSM19_data/tfue.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects nine streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects specific streams\n",
    "kr_stream1 = kingrichard[kingrichard['video_id'] == '264485130']\n",
    "kr_stream2 = kingrichard[kingrichard['video_id'] == '269543679']\n",
    "kr_stream3 = kingrichard[kingrichard['video_id'] == '270350156']\n",
    "#Merges together\n",
    "kr_short = pd.concat([kr_stream1, kr_stream2, kr_stream3], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects specific streams\n",
    "sc_stream1 = scarra[scarra['video_id'] == '265494216']\n",
    "sc_stream2 = scarra[scarra['video_id'] == '262866347']\n",
    "#Merges together\n",
    "sc_short = pd.concat([sc_stream1, sc_stream2], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects specific streams\n",
    "cb_stream1 = xchocobars[xchocobars['video_id'] == '275994445']\n",
    "cb_stream2 = xchocobars[xchocobars['video_id'] == '274073677']\n",
    "#Merges together\n",
    "cb_short = pd.concat([cb_stream1, cb_stream2], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects specific streams\n",
    "tf_stream1 = tfue[tfue['video_id'] == '265017626']\n",
    "tf_stream2 = tfue[tfue['video_id'] == '266069120']\n",
    "#Merges together\n",
    "tf_short = pd.concat([tf_stream1, tf_stream2], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges stream subsets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [kr_short, sc_short, cb_short, tf_short]\n",
    "final_df = pd.concat(dfs, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find only users and drops admin/staff comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects users\n",
    "df = final_df[final_df.commenter_type == 'user']\n",
    "#Gets rid of column as all same value now\n",
    "df = df.drop('commenter_type', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any edited Twitch chats (can't tell if commentor or mod edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts columns to datetime for easy use\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "#Subtracts rows to see if there's a non-0 value\n",
    "df['edited'] = df.apply(lambda row: row.updated_at - row.created_at, axis=1)\n",
    "#Only keeps rows that weren't edited\n",
    "no_edits = df[df['edited'] == pd.Timedelta(\"0 days 00:00:00\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create twitch_chat column that has no emoticons in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to replace chats\n",
    "def replace_text(fragments):\n",
    "    twitch_chat = ''\n",
    "    for d in fragments:\n",
    "        #Finds text in fragments and adds it to twitch_chat\n",
    "        if 'text' in d.keys():\n",
    "            #If no previous chat creates one\n",
    "            if len(twitch_chat) == 0:\n",
    "                items = list(d.items())\n",
    "                twitch_chat = items[0][1]\n",
    "            #If previous text in fragments, adds to it\n",
    "            else:\n",
    "                items = list(d.items())\n",
    "                twitch_chat = twitch_chat + ' ' + items[0][1]\n",
    "    return twitch_chat\n",
    "\n",
    "#Column with only words, no emoticons\n",
    "no_edits['twitch_chat'] = no_edits['fragments'].apply(replace_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break emoticons out into a list in their own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to isolate emotes\n",
    "def emoticon_list(fragments):\n",
    "    emotes = []\n",
    "    for d in fragments:\n",
    "        #Finds if any emotes and adds to list\n",
    "        if 'emoticon_id' in d.keys():\n",
    "            items = list(d.items())\n",
    "            emotes.append(items[0][1])\n",
    "    #If no emotes in chat returns None\n",
    "    if emotes == []:\n",
    "        return ['None']\n",
    "    return emotes\n",
    "\n",
    "#Creates emotes only column\n",
    "no_edits['emotes'] = no_edits['fragments'].apply(emoticon_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of any rows that are chat commands (start with !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds rows that start with !\n",
    "command = no_edits['twitch_chat'].str.startswith('!') \n",
    "#Drops them from the dataframe\n",
    "no_edits = no_edits[~command].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drops the columns just used for creating other features that are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edits = no_edits.drop(['fragments', 'updated_at', 'edited'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edits.to_csv('../data/small_merged_chats', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

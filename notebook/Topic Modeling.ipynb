{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c752dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Imports libraries for text cleaning and manipulation\n",
    "import nltk\n",
    "import re\n",
    "import collections\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "#Imports libraries for modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, recall_score, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "#Imports dataset\n",
    "df = pd.read_csv('../data/small_merged_chats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca74747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['body'])\n",
    "\n",
    "\n",
    "def ad(chat):\n",
    "    result = False\n",
    "    #Change result to True if link present in chat\n",
    "    result = bool(re.search(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', chat))\n",
    "    result = bool(re.search(r'http\\S+', chat))\n",
    "    return result\n",
    "\n",
    "#Makes ad column and gets rid of any ad messages\n",
    "df['is_ad'] = df['body'].apply(ad)\n",
    "df = df[df['is_ad'] == False]\n",
    "\n",
    "\n",
    "def emoji_shorten(chat):\n",
    "    chat = re.sub(r'(?i) \\bpog(\\w)*\\b |\\bpog(\\w)*\\b', 'pog', chat)\n",
    "    chat = re.sub(r'(?i) \\blul(\\w)*\\b |\\blul(\\w)*\\b', 'lul', chat)\n",
    "    chat = re.sub(r'(?i) \\bkappa(\\w)*\\b |\\bkappa(\\w)*\\b', 'kappa', chat)\n",
    "    return chat\n",
    "\n",
    "#Creates new column with emojis shortened to simple form\n",
    "df['chats'] = df.body.apply(lambda x: emoji_shorten(x))\n",
    "\n",
    "\n",
    "df = df.drop(columns = ['body', 'commenter_id', 'is_ad', 'created_at', \n",
    "                  'offset', 'twitch_chat', 'emotes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64982066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>chats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66691674</td>\n",
       "      <td>264485130</td>\n",
       "      <td>wazupp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66691674</td>\n",
       "      <td>264485130</td>\n",
       "      <td>Yo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66691674</td>\n",
       "      <td>264485130</td>\n",
       "      <td>What up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66691674</td>\n",
       "      <td>264485130</td>\n",
       "      <td>yes!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66691674</td>\n",
       "      <td>264485130</td>\n",
       "      <td>Wassgud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103926</th>\n",
       "      <td>60056333</td>\n",
       "      <td>266069120</td>\n",
       "      <td>ello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103927</th>\n",
       "      <td>60056333</td>\n",
       "      <td>266069120</td>\n",
       "      <td>eyyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103928</th>\n",
       "      <td>60056333</td>\n",
       "      <td>266069120</td>\n",
       "      <td>Kingrichard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103929</th>\n",
       "      <td>60056333</td>\n",
       "      <td>266069120</td>\n",
       "      <td>BrokeBack My belly is fat, my brain has delay,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103930</th>\n",
       "      <td>60056333</td>\n",
       "      <td>266069120</td>\n",
       "      <td>jasonr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102700 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        channel_id   video_id  \\\n",
       "0         66691674  264485130   \n",
       "1         66691674  264485130   \n",
       "2         66691674  264485130   \n",
       "3         66691674  264485130   \n",
       "4         66691674  264485130   \n",
       "...            ...        ...   \n",
       "103926    60056333  266069120   \n",
       "103927    60056333  266069120   \n",
       "103928    60056333  266069120   \n",
       "103929    60056333  266069120   \n",
       "103930    60056333  266069120   \n",
       "\n",
       "                                                    chats  \n",
       "0                                                  wazupp  \n",
       "1                                                      Yo  \n",
       "2                                                 What up  \n",
       "3                                                  yes!!!  \n",
       "4                                                 Wassgud  \n",
       "...                                                   ...  \n",
       "103926                                               ello  \n",
       "103927                                               eyyy  \n",
       "103928                                        Kingrichard  \n",
       "103929  BrokeBack My belly is fat, my brain has delay,...  \n",
       "103930                                             jasonr  \n",
       "\n",
       "[102700 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126c0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces pos tags with lemmatize compatable tags\n",
    "def pos_replace(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "#Makes list of punctuation to exclude, keeps certain symbols\n",
    "punct = list(string.punctuation)\n",
    "keep_punct = ['?', '!', '@', ',', '.']\n",
    "punct = [p for p in punct if p not in keep_punct]\n",
    "\n",
    "#Removes non-ASCII characters (aka emojis that cant be converted to original symbol)\n",
    "def remove_junk(tweet):\n",
    "    return ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "\n",
    "def chat_tokenizer(doc):\n",
    "    #Gets rid of weird characters\n",
    "    doc = remove_junk(doc)\n",
    "    #Tokenizes using NLTK Twitter Tokenizer as chats like tweets\n",
    "    chat_token = TweetTokenizer(strip_handles = True)\n",
    "    doc = chat_token.tokenize(doc)\n",
    "    #Strips extra puntuation I don't want to keep\n",
    "    doc = [w for w in doc if w not in punct]\n",
    "    #Lemmatizes tokens\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(w[0], pos_replace(w[1])) for w in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.chats = df.chats.apply(chat_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a3940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df.chats)\n",
    "\n",
    "# Create Corpus\n",
    "texts = df.chats\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aed86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 3\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "#For saving/loading models\n",
    "\n",
    "# with open(LDAvis_data_filepath, 'wb') as f:\n",
    "#     pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "# with open(LDAvis_data_filepath, 'rb') as f:\n",
    "#     LDAvis_prepared = pickle.load(f)\n",
    "#pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21f050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor)",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
